{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac8231",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:21.792036Z",
     "iopub.status.busy": "2023-12-29T11:45:21.791500Z",
     "iopub.status.idle": "2023-12-29T11:45:25.060408Z",
     "shell.execute_reply": "2023-12-29T11:45:25.059107Z"
    },
    "papermill": {
     "duration": 3.304915,
     "end_time": "2023-12-29T11:45:25.064023",
     "exception": false,
     "start_time": "2023-12-29T11:45:21.759108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For displaying all of the columns in dataframes\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# For data modeling\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# For metrics and helpful functions\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,\\\n",
    "f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report,make_scorer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.tree import plot_tree\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For saving models\n",
    "import pickle\n",
    "\n",
    "# For Warnings Ignore\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40ac21c",
   "metadata": {
    "papermill": {
     "duration": 0.031687,
     "end_time": "2023-12-29T11:45:25.126414",
     "exception": false,
     "start_time": "2023-12-29T11:45:25.094727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7eb606",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:25.191619Z",
     "iopub.status.busy": "2023-12-29T11:45:25.191067Z",
     "iopub.status.idle": "2023-12-29T11:45:25.224454Z",
     "shell.execute_reply": "2023-12-29T11:45:25.223356Z"
    },
    "papermill": {
     "duration": 0.069197,
     "end_time": "2023-12-29T11:45:25.227457",
     "exception": false,
     "start_time": "2023-12-29T11:45:25.158260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# /kaggle/input/titanic/train.csv\n",
    "# /kaggle/input/titanic/test.csv\n",
    "# /kaggle/input/titanic/gender_submission.csv\n",
    "\n",
    "df_train = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd9662",
   "metadata": {
    "papermill": {
     "duration": 0.029379,
     "end_time": "2023-12-29T11:45:25.287318",
     "exception": false,
     "start_time": "2023-12-29T11:45:25.257939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Exploration (Initial EDA and data cleaning)\n",
    "\n",
    "- Understand your variables\n",
    "- Clean your dataset (missing data, redundant data, outliers) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9a39fb",
   "metadata": {
    "papermill": {
     "duration": 0.029556,
     "end_time": "2023-12-29T11:45:25.346857",
     "exception": false,
     "start_time": "2023-12-29T11:45:25.317301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* PassengerId is the unique id of the row and it doesn't have any effect on target\n",
    "* Survived is the target variable we are trying to predict (0 or 1):\n",
    "    * 1 = Survived\n",
    "    * 0 = Not Survived\n",
    "* Pclass (Passenger Class) is the socio-economic status of the passenger and it is a categorical ordinal feature * which has 3 unique values (1, 2 or 3):\n",
    "    * 1 = Upper Class\n",
    "    * 2 = Middle Class\n",
    "    * 3 = Lower Class\n",
    "* Name, Sex and Age are self-explanatory\n",
    "* SibSp is the total number of the passengers' siblings and spouse\n",
    "* Parch is the total number of the passengers' parents and children\n",
    "* Ticket is the ticket number of the passenger\n",
    "* Fare is the passenger fare\n",
    "* Cabin is the cabin number of the passenger\n",
    "* Embarked is port of embarkation and it is a categorical feature which has 3 unique values (C, Q or S):\n",
    "    * C = Cherbourg\n",
    "    * Q = Queenstown\n",
    "    * S = Southampton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd937d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:25.475359Z",
     "iopub.status.busy": "2023-12-29T11:45:25.474921Z",
     "iopub.status.idle": "2023-12-29T11:45:25.517410Z",
     "shell.execute_reply": "2023-12-29T11:45:25.515456Z"
    },
    "papermill": {
     "duration": 0.143667,
     "end_time": "2023-12-29T11:45:25.520118",
     "exception": false,
     "start_time": "2023-12-29T11:45:25.376451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b9cb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:25.582516Z",
     "iopub.status.busy": "2023-12-29T11:45:25.582072Z",
     "iopub.status.idle": "2023-12-29T11:45:25.625320Z",
     "shell.execute_reply": "2023-12-29T11:45:25.624025Z"
    },
    "papermill": {
     "duration": 0.077501,
     "end_time": "2023-12-29T11:45:25.627971",
     "exception": false,
     "start_time": "2023-12-29T11:45:25.550470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7e030",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:25.691061Z",
     "iopub.status.busy": "2023-12-29T11:45:25.690620Z",
     "iopub.status.idle": "2023-12-29T11:45:25.727717Z",
     "shell.execute_reply": "2023-12-29T11:45:25.726491Z"
    },
    "papermill": {
     "duration": 0.071709,
     "end_time": "2023-12-29T11:45:25.730321",
     "exception": false,
     "start_time": "2023-12-29T11:45:25.658612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36817489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:25.794596Z",
     "iopub.status.busy": "2023-12-29T11:45:25.793926Z",
     "iopub.status.idle": "2023-12-29T11:45:25.800704Z",
     "shell.execute_reply": "2023-12-29T11:45:25.799071Z"
    },
    "papermill": {
     "duration": 0.042172,
     "end_time": "2023-12-29T11:45:25.803158",
     "exception": false,
     "start_time": "2023-12-29T11:45:25.760986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get the shape of data \n",
    "print(f'train : {df_train.shape} \\ntest : {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dca5a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:25.867810Z",
     "iopub.status.busy": "2023-12-29T11:45:25.867131Z",
     "iopub.status.idle": "2023-12-29T11:45:25.880314Z",
     "shell.execute_reply": "2023-12-29T11:45:25.878671Z"
    },
    "papermill": {
     "duration": 0.049259,
     "end_time": "2023-12-29T11:45:25.883195",
     "exception": false,
     "start_time": "2023-12-29T11:45:25.833936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check for duplicates\n",
    "print(f'train : {df_train.duplicated().sum()} \\ntest : {df_test.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935b770",
   "metadata": {
    "papermill": {
     "duration": 0.03165,
     "end_time": "2023-12-29T11:45:25.946409",
     "exception": false,
     "start_time": "2023-12-29T11:45:25.914759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Which features are available in the dataset?\n",
    "\n",
    "#### Which features are categorical?\n",
    "\n",
    "These values classify the samples into sets of similar samples. Within categorical features are the values nominal, ordinal, ratio, or interval based? Among other things this helps us select the appropriate plots for visualization.\n",
    "\n",
    "* Nominal: Survived(Binary), Sex and Embarked.\n",
    "* Ordinal: Pclass.\n",
    "\n",
    "#### Which features are numerical?\n",
    "\n",
    "Which features are numerical? These values change from sample to sample. Within numerical features are the values discrete, continuous, or timeseries based? Among other things this helps us select the appropriate plots for visualization.\n",
    "\n",
    "* Continous: Age, Fare.\n",
    "* Discrete: SibSp, Parch.\n",
    "\n",
    "#### Which features are mixed data types?\n",
    "\n",
    "Numerical, alphanumeric data within same feature. These are candidates for correcting goal.\n",
    "\n",
    "* Ticket is a mix of numeric and alphanumeric data types. Cabin is alphanumeric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd66d657",
   "metadata": {
    "papermill": {
     "duration": 0.031513,
     "end_time": "2023-12-29T11:45:26.009300",
     "exception": false,
     "start_time": "2023-12-29T11:45:25.977787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### We are going to merge the test and train data to fix the missing values then split them again afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708639b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:26.075419Z",
     "iopub.status.busy": "2023-12-29T11:45:26.074302Z",
     "iopub.status.idle": "2023-12-29T11:45:26.108934Z",
     "shell.execute_reply": "2023-12-29T11:45:26.108077Z"
    },
    "papermill": {
     "duration": 0.070659,
     "end_time": "2023-12-29T11:45:26.111329",
     "exception": false,
     "start_time": "2023-12-29T11:45:26.040670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_train, df_test]).reset_index(drop=True)\n",
    "df_all.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c881af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:26.190446Z",
     "iopub.status.busy": "2023-12-29T11:45:26.189205Z",
     "iopub.status.idle": "2023-12-29T11:45:26.729802Z",
     "shell.execute_reply": "2023-12-29T11:45:26.728810Z"
    },
    "papermill": {
     "duration": 0.587005,
     "end_time": "2023-12-29T11:45:26.732503",
     "exception": false,
     "start_time": "2023-12-29T11:45:26.145498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select only numeric columns for the heatmap\n",
    "numeric_columns = df_all.select_dtypes(include='number')\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "heatmap_data = numeric_columns.corr()  # Calculate correlation matrix\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Heatmap for Numeric Data in df_all')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352bb27b",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:26.802036Z",
     "iopub.status.busy": "2023-12-29T11:45:26.801254Z",
     "iopub.status.idle": "2023-12-29T11:45:27.112368Z",
     "shell.execute_reply": "2023-12-29T11:45:27.111086Z"
    },
    "papermill": {
     "duration": 0.349274,
     "end_time": "2023-12-29T11:45:27.115302",
     "exception": false,
     "start_time": "2023-12-29T11:45:26.766028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate missing data percentage for each column\n",
    "missing_count = df_all.isnull().sum()\n",
    "missing_percentage = (missing_count / len(df_all)) * 100\n",
    "missing_data = pd.DataFrame({'Column': missing_percentage.index, 'MissingPercentage': missing_percentage.values, 'MissingCount': missing_count.values})\n",
    "\n",
    "# Filter out columns with zero missing values\n",
    "missing_data = missing_data[missing_data['MissingPercentage'] > 0]\n",
    "\n",
    "# Round the missing percentage to 3 decimal places\n",
    "missing_data['MissingPercentage'] = missing_data['MissingPercentage'].round(3)\n",
    "missing_data = missing_data.sort_values(by='MissingPercentage', ascending=False)\n",
    "# Plot the missing data as a stacked bar chart using seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='Column', y='MissingPercentage', data=missing_data, palette='viridis')\n",
    "\n",
    "# Add the rounded missing value percentages inside the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height():.2f}%', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "plt.title('Missing Data Stacked Bar Chart')\n",
    "plt.xlabel('Columns')\n",
    "plt.ylabel('Missing Data Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e171574",
   "metadata": {
    "papermill": {
     "duration": 0.036316,
     "end_time": "2023-12-29T11:45:27.186601",
     "exception": false,
     "start_time": "2023-12-29T11:45:27.150285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa8053",
   "metadata": {
    "papermill": {
     "duration": 0.033649,
     "end_time": "2023-12-29T11:45:27.255583",
     "exception": false,
     "start_time": "2023-12-29T11:45:27.221934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "cabin has 77% missing values its a huge number , we could remove this feature from our selection as we build the model, or we can try to look for clues in the other features to replace the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07b0625",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:27.326742Z",
     "iopub.status.busy": "2023-12-29T11:45:27.326240Z",
     "iopub.status.idle": "2023-12-29T11:45:27.335413Z",
     "shell.execute_reply": "2023-12-29T11:45:27.334095Z"
    },
    "papermill": {
     "duration": 0.047292,
     "end_time": "2023-12-29T11:45:27.338225",
     "exception": false,
     "start_time": "2023-12-29T11:45:27.290933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign all the null values to N\n",
    "df_all.Cabin.fillna(\"N\", inplace=True)\n",
    "\n",
    "# group these cabins according to the letter of the cabin name \n",
    "df_all.Cabin = [str(i)[0] for i in df_all.Cabin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7d29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:27.408210Z",
     "iopub.status.busy": "2023-12-29T11:45:27.407783Z",
     "iopub.status.idle": "2023-12-29T11:45:27.431479Z",
     "shell.execute_reply": "2023-12-29T11:45:27.430288Z"
    },
    "papermill": {
     "duration": 0.061368,
     "end_time": "2023-12-29T11:45:27.434075",
     "exception": false,
     "start_time": "2023-12-29T11:45:27.372707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3580105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:27.506374Z",
     "iopub.status.busy": "2023-12-29T11:45:27.505944Z",
     "iopub.status.idle": "2023-12-29T11:45:27.520876Z",
     "shell.execute_reply": "2023-12-29T11:45:27.519485Z"
    },
    "papermill": {
     "duration": 0.053987,
     "end_time": "2023-12-29T11:45:27.523637",
     "exception": false,
     "start_time": "2023-12-29T11:45:27.469650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group by 'Cabin' and calculate the mean fare for each group\n",
    "fare_mean_by_cabin = df_all.groupby('Cabin')['Fare'].mean().reset_index()\n",
    "fare_mean_by_cabin = fare_mean_by_cabin.sort_values(by='Fare', ascending=False).reset_index(drop=True).round()\n",
    "\n",
    "\n",
    "# Print the result\n",
    "print(fare_mean_by_cabin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4449b925",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:27.594507Z",
     "iopub.status.busy": "2023-12-29T11:45:27.594049Z",
     "iopub.status.idle": "2023-12-29T11:45:27.607073Z",
     "shell.execute_reply": "2023-12-29T11:45:27.605638Z"
    },
    "papermill": {
     "duration": 0.051633,
     "end_time": "2023-12-29T11:45:27.609722",
     "exception": false,
     "start_time": "2023-12-29T11:45:27.558089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# remove N\n",
    "fare_mean_by_cabin = fare_mean_by_cabin[fare_mean_by_cabin['Cabin'] != 'N']\n",
    "\n",
    "# create a dict\n",
    "replacement_values = fare_mean_by_cabin[['Cabin', 'Fare']].to_dict(orient='records')\n",
    "\n",
    "# Sort the list of dictionaries based on 'Fare' values in descending order\n",
    "replacement_values = sorted(replacement_values, key=lambda x: x['Fare'], reverse=True)\n",
    "\n",
    "pprint(replacement_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c776492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:27.684898Z",
     "iopub.status.busy": "2023-12-29T11:45:27.684459Z",
     "iopub.status.idle": "2023-12-29T11:45:27.699386Z",
     "shell.execute_reply": "2023-12-29T11:45:27.698222Z"
    },
    "papermill": {
     "duration": 0.054792,
     "end_time": "2023-12-29T11:45:27.701894",
     "exception": false,
     "start_time": "2023-12-29T11:45:27.647102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Estimate Cabin based on Fare \n",
    "def cabin_estimator(i):\n",
    "    fare_ranges = [(0, 16, 'G'), (16, 27, 'F'), (27, 38, 'T'), (38, 47, 'A'), (47, 53, 'E'), (53, 54, 'D'), (54, 116, 'C')]\n",
    "    for start, end, cabin in fare_ranges:\n",
    "        if start <= i < end:\n",
    "            return cabin\n",
    "    return \"B\"  # Default value if not in any range\n",
    "\n",
    "df_all['Cabin'] = df_all.Fare.apply(lambda x: cabin_estimator(x))\n",
    "\n",
    "# check \n",
    "(df_all['Cabin'] == 'N').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7776b05d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:27.773756Z",
     "iopub.status.busy": "2023-12-29T11:45:27.772648Z",
     "iopub.status.idle": "2023-12-29T11:45:28.071408Z",
     "shell.execute_reply": "2023-12-29T11:45:28.070133Z"
    },
    "papermill": {
     "duration": 0.337619,
     "end_time": "2023-12-29T11:45:28.074041",
     "exception": false,
     "start_time": "2023-12-29T11:45:27.736422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count occurrences of each 'Cabin' value\n",
    "cabin_counts = df_all['Cabin'].value_counts()\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "cabin_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title('Cabin Value Counts')\n",
    "plt.xlabel('Cabin')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03322db",
   "metadata": {
    "papermill": {
     "duration": 0.034754,
     "end_time": "2023-12-29T11:45:28.144403",
     "exception": false,
     "start_time": "2023-12-29T11:45:28.109649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a048880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:28.217390Z",
     "iopub.status.busy": "2023-12-29T11:45:28.216995Z",
     "iopub.status.idle": "2023-12-29T11:45:28.225372Z",
     "shell.execute_reply": "2023-12-29T11:45:28.224176Z"
    },
    "papermill": {
     "duration": 0.048876,
     "end_time": "2023-12-29T11:45:28.227976",
     "exception": false,
     "start_time": "2023-12-29T11:45:28.179100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all['Age'].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d718e093",
   "metadata": {
    "papermill": {
     "duration": 0.035354,
     "end_time": "2023-12-29T11:45:28.299307",
     "exception": false,
     "start_time": "2023-12-29T11:45:28.263953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "19% of age values are missing, age might be a huge factor in surviving, in the light of how fit you are to run up the stairs and fight the cold weather in the sea. we should look for clause first before dropping the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6cdba6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:28.372415Z",
     "iopub.status.busy": "2023-12-29T11:45:28.372021Z",
     "iopub.status.idle": "2023-12-29T11:45:28.381208Z",
     "shell.execute_reply": "2023-12-29T11:45:28.379892Z"
    },
    "papermill": {
     "duration": 0.049509,
     "end_time": "2023-12-29T11:45:28.383836",
     "exception": false,
     "start_time": "2023-12-29T11:45:28.334327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all['Name'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4f68c",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:28.456541Z",
     "iopub.status.busy": "2023-12-29T11:45:28.456139Z",
     "iopub.status.idle": "2023-12-29T11:45:29.661945Z",
     "shell.execute_reply": "2023-12-29T11:45:29.660780Z"
    },
    "papermill": {
     "duration": 1.249173,
     "end_time": "2023-12-29T11:45:29.668247",
     "exception": false,
     "start_time": "2023-12-29T11:45:28.419074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "# Concatenate the text column values into a single string\n",
    "text = ' '.join(df_all['Name'])\n",
    "\n",
    "# Create a WordCloud object with collocations set to False\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=STOPWORDS, collocations=False).generate(text)\n",
    "\n",
    "# Display the WordCloud using matplotlib\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4ade0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:29.755197Z",
     "iopub.status.busy": "2023-12-29T11:45:29.754795Z",
     "iopub.status.idle": "2023-12-29T11:45:29.982159Z",
     "shell.execute_reply": "2023-12-29T11:45:29.981002Z"
    },
    "papermill": {
     "duration": 0.273823,
     "end_time": "2023-12-29T11:45:29.984661",
     "exception": false,
     "start_time": "2023-12-29T11:45:29.710838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract the intials \n",
    "# extract any words before a dot\n",
    "df_all['Initial']=0\n",
    "for i in df_all:\n",
    "    df_all['Initial']=df_all.Name.str.extract('([A-Za-z]+)\\.') #lets extract the Salutations\n",
    "\n",
    "# check the extraction\n",
    "pd.crosstab(df_all.Initial,df_all.Sex).T.style.background_gradient(cmap='summer_r')  # Checking the Initials with the Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97e8470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:30.072183Z",
     "iopub.status.busy": "2023-12-29T11:45:30.071515Z",
     "iopub.status.idle": "2023-12-29T11:45:30.087391Z",
     "shell.execute_reply": "2023-12-29T11:45:30.086096Z"
    },
    "papermill": {
     "duration": 0.063043,
     "end_time": "2023-12-29T11:45:30.090079",
     "exception": false,
     "start_time": "2023-12-29T11:45:30.027036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don', 'Dona'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr', 'Mrs'],inplace=True)\n",
    "df_all.groupby('Initial')['Age'].mean()  # lets check the average age by Initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5c5a8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:30.178132Z",
     "iopub.status.busy": "2023-12-29T11:45:30.177023Z",
     "iopub.status.idle": "2023-12-29T11:45:30.192026Z",
     "shell.execute_reply": "2023-12-29T11:45:30.190750Z"
    },
    "papermill": {
     "duration": 0.06298,
     "end_time": "2023-12-29T11:45:30.195796",
     "exception": false,
     "start_time": "2023-12-29T11:45:30.132816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define mean ages by initial\n",
    "mean_ages = {'Mr': 33, 'Mrs': 37, 'Master': 5, 'Miss': 22, 'Other': 45}\n",
    "\n",
    "# Assigning NaN values with the mean ages\n",
    "for initial, mean_age in mean_ages.items():\n",
    "    df_all.loc[(df_all.Age.isnull()) & (df_all.Initial == initial), 'Age'] = mean_age\n",
    "\n",
    "# Check if any null values are left\n",
    "print(df_all.Age.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d345dc",
   "metadata": {
    "papermill": {
     "duration": 0.042531,
     "end_time": "2023-12-29T11:45:30.281054",
     "exception": false,
     "start_time": "2023-12-29T11:45:30.238523",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Embarked\n",
    "Embarked feature takes S, Q, C values based on port of embarkation. It looks like there are only two null values( ~ 0.22 %) in the Embarked feature, we can replace these with the mode value \"S\". However, let's dig a little deeper. Let's see what are those two null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307e61e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:30.368629Z",
     "iopub.status.busy": "2023-12-29T11:45:30.367501Z",
     "iopub.status.idle": "2023-12-29T11:45:30.377173Z",
     "shell.execute_reply": "2023-12-29T11:45:30.376104Z"
    },
    "papermill": {
     "duration": 0.056202,
     "end_time": "2023-12-29T11:45:30.379714",
     "exception": false,
     "start_time": "2023-12-29T11:45:30.323512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe203c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:30.468596Z",
     "iopub.status.busy": "2023-12-29T11:45:30.467823Z",
     "iopub.status.idle": "2023-12-29T11:45:30.485505Z",
     "shell.execute_reply": "2023-12-29T11:45:30.484624Z"
    },
    "papermill": {
     "duration": 0.064973,
     "end_time": "2023-12-29T11:45:30.487835",
     "exception": false,
     "start_time": "2023-12-29T11:45:30.422862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all[df_all['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a613fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:30.576413Z",
     "iopub.status.busy": "2023-12-29T11:45:30.575954Z",
     "iopub.status.idle": "2023-12-29T11:45:30.586776Z",
     "shell.execute_reply": "2023-12-29T11:45:30.585519Z"
    },
    "papermill": {
     "duration": 0.058714,
     "end_time": "2023-12-29T11:45:30.589309",
     "exception": false,
     "start_time": "2023-12-29T11:45:30.530595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all.groupby('Embarked')['Fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc9b290",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:30.677924Z",
     "iopub.status.busy": "2023-12-29T11:45:30.677489Z",
     "iopub.status.idle": "2023-12-29T11:45:30.687329Z",
     "shell.execute_reply": "2023-12-29T11:45:30.686097Z"
    },
    "papermill": {
     "duration": 0.057457,
     "end_time": "2023-12-29T11:45:30.689873",
     "exception": false,
     "start_time": "2023-12-29T11:45:30.632416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replacing the null values with C as null values fares equal 80.\n",
    "df_all['Embarked'].fillna('C', inplace = True)\n",
    "\n",
    "# check\n",
    "df_all['Embarked'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50257a1a",
   "metadata": {
    "papermill": {
     "duration": 0.043765,
     "end_time": "2023-12-29T11:45:30.777300",
     "exception": false,
     "start_time": "2023-12-29T11:45:30.733535",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b6836f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:30.866516Z",
     "iopub.status.busy": "2023-12-29T11:45:30.866060Z",
     "iopub.status.idle": "2023-12-29T11:45:30.885409Z",
     "shell.execute_reply": "2023-12-29T11:45:30.883961Z"
    },
    "papermill": {
     "duration": 0.066919,
     "end_time": "2023-12-29T11:45:30.888020",
     "exception": false,
     "start_time": "2023-12-29T11:45:30.821101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all[df_all['Fare'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87698932",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:30.979082Z",
     "iopub.status.busy": "2023-12-29T11:45:30.978652Z",
     "iopub.status.idle": "2023-12-29T11:45:30.989116Z",
     "shell.execute_reply": "2023-12-29T11:45:30.987958Z"
    },
    "papermill": {
     "duration": 0.058925,
     "end_time": "2023-12-29T11:45:30.991389",
     "exception": false,
     "start_time": "2023-12-29T11:45:30.932464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Embarked from S port the Fare mean is 27.5\n",
    "df_all['Fare'].fillna(27.5, inplace = True)\n",
    "\n",
    "# check\n",
    "df_all['Fare'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226df5a",
   "metadata": {
    "papermill": {
     "duration": 0.042986,
     "end_time": "2023-12-29T11:45:31.078553",
     "exception": false,
     "start_time": "2023-12-29T11:45:31.035567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering\n",
    "##### Using practical, statistical, and data science knowledge to select, transform, or extract characteristics from raw data.\n",
    " ### **1. Feature Selection:**\n",
    "\n",
    "- **Purpose:**\n",
    "    - Choosing variables to use as predictor variables for the model.\n",
    "- **Considerations:**\n",
    "    - Eliminate redundant and irrelevant features.\n",
    "    - Enhances model performance by focusing on informative features.\n",
    "\n",
    "### **2. Feature Transformation:**\n",
    "\n",
    "- **Purpose:**\n",
    "    - Modify existing features to improve model training accuracy.\n",
    "- **Log Normalization:**\n",
    "    - Transforming skewed continuous variables using the natural logarithm.\n",
    "    - Converts log-normal distributions to normal distributions.\n",
    "- **Scaling:**\n",
    "    - **Normalization (MinMaxScaler):**\n",
    "        - Transforms data to a range between 0 and 1.\n",
    "        - Prevents features with large values from dominating the model.\n",
    "    - **Standardization (StandardScaler):**\n",
    "        - Gives features a mean of 0 and a standard deviation of 1.\n",
    "        - Useful for machine learning algorithms sensitive to feature magnitudes.\n",
    "- **Encoding:**\n",
    "    - **One-Hot Encoding:**\n",
    "        - Converts categorical data into binary vectors.\n",
    "        - Creates binary columns for each category.\n",
    "    - **Ordinal Encoding:**\n",
    "        - Used for categorical data with inherent order or ranking.\n",
    "        - Assigns numerical values while preserving the order.\n",
    "\n",
    "### **3. Feature Extraction:**\n",
    "\n",
    "- **Definition:**\n",
    "    - Producing new features from existing ones to enhance predictive power.\n",
    "- **Example:**\n",
    "    - Creating \"Days Since Last Purchase\" from \"Date of Last Purchase.\"\n",
    "    - Offers valuable insights for model predictions.\n",
    "\n",
    "\n",
    "### **Types of Features:**\n",
    "\n",
    "   - **Predictive Features:**\n",
    "        - Independently informative for predicting the target.\n",
    "   - **Interactive Features:**\n",
    "        - Gain predictiveness when combined with other features.\n",
    "   - **Irrelevant Features:**\n",
    "        - Lack useful information for prediction.\n",
    "   - **Redundant Features:**\n",
    "        - Highly correlated, providing no new information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb7fb0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:31.166759Z",
     "iopub.status.busy": "2023-12-29T11:45:31.165928Z",
     "iopub.status.idle": "2023-12-29T11:45:31.205547Z",
     "shell.execute_reply": "2023-12-29T11:45:31.204369Z"
    },
    "papermill": {
     "duration": 0.086429,
     "end_time": "2023-12-29T11:45:31.208103",
     "exception": false,
     "start_time": "2023-12-29T11:45:31.121674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform catgorial data Sex, Cabin and Embarked into numruical form.\n",
    "df_all = pd.get_dummies(df_all, columns=['Sex', 'Cabin', 'Embarked'], drop_first=True)\n",
    "\n",
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298dfbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:31.297949Z",
     "iopub.status.busy": "2023-12-29T11:45:31.297497Z",
     "iopub.status.idle": "2023-12-29T11:45:31.334767Z",
     "shell.execute_reply": "2023-12-29T11:45:31.333564Z"
    },
    "papermill": {
     "duration": 0.085469,
     "end_time": "2023-12-29T11:45:31.337551",
     "exception": false,
     "start_time": "2023-12-29T11:45:31.252082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract a more valuable feature from sibsp and parch as family size.\n",
    "df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1  # Adding 1 for the person himself\n",
    "\n",
    "# Drop 'SibSp' and 'Parch'\n",
    "df_all = df_all.drop(['SibSp', 'Parch'], axis=1)\n",
    "\n",
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f524ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:31.430979Z",
     "iopub.status.busy": "2023-12-29T11:45:31.430509Z",
     "iopub.status.idle": "2023-12-29T11:45:31.438345Z",
     "shell.execute_reply": "2023-12-29T11:45:31.437171Z"
    },
    "papermill": {
     "duration": 0.056617,
     "end_time": "2023-12-29T11:45:31.440815",
     "exception": false,
     "start_time": "2023-12-29T11:45:31.384198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all['Family_Size'].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed808b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:31.533304Z",
     "iopub.status.busy": "2023-12-29T11:45:31.532237Z",
     "iopub.status.idle": "2023-12-29T11:45:33.013668Z",
     "shell.execute_reply": "2023-12-29T11:45:33.012737Z"
    },
    "papermill": {
     "duration": 1.531122,
     "end_time": "2023-12-29T11:45:33.017580",
     "exception": false,
     "start_time": "2023-12-29T11:45:31.486458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(20, 20), ncols=2, nrows=2)\n",
    "plt.subplots_adjust(right=1.5)\n",
    "\n",
    "sns.barplot(x=df_all['Family_Size'].value_counts().index, y=df_all['Family_Size'].value_counts().values, ax=axs[0][0])\n",
    "sns.countplot(x='Family_Size', hue='Survived', data=df_all, ax=axs[0][1])\n",
    "\n",
    "axs[0][0].set_title('Family Size Feature Value Counts', size=20, y=1.05)\n",
    "axs[0][1].set_title('Survival Counts in Family Size ', size=20, y=1.05)\n",
    "\n",
    "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
    "df_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)\n",
    "\n",
    "sns.barplot(x=df_all['Family_Size_Grouped'].value_counts().index, y=df_all['Family_Size_Grouped'].value_counts().values, ax=axs[1][0])\n",
    "sns.countplot(x='Family_Size_Grouped', hue='Survived', data=df_all, ax=axs[1][1])\n",
    "\n",
    "axs[1][0].set_title('Family Size Feature Value Counts After Grouping', size=20, y=1.05)\n",
    "axs[1][1].set_title('Survival Counts in Family Size After Grouping', size=20, y=1.05)\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i][1].legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 20})\n",
    "    for j in range(2):\n",
    "        axs[i][j].tick_params(axis='x', labelsize=20)\n",
    "        axs[i][j].tick_params(axis='y', labelsize=20)\n",
    "        axs[i][j].set_xlabel('')\n",
    "        axs[i][j].set_ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e18f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:33.120993Z",
     "iopub.status.busy": "2023-12-29T11:45:33.119863Z",
     "iopub.status.idle": "2023-12-29T11:45:33.153848Z",
     "shell.execute_reply": "2023-12-29T11:45:33.152702Z"
    },
    "papermill": {
     "duration": 0.087954,
     "end_time": "2023-12-29T11:45:33.156298",
     "exception": false,
     "start_time": "2023-12-29T11:45:33.068344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all.head(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a150c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:33.260209Z",
     "iopub.status.busy": "2023-12-29T11:45:33.259438Z",
     "iopub.status.idle": "2023-12-29T11:45:33.276311Z",
     "shell.execute_reply": "2023-12-29T11:45:33.275117Z"
    },
    "papermill": {
     "duration": 0.071576,
     "end_time": "2023-12-29T11:45:33.278949",
     "exception": false,
     "start_time": "2023-12-29T11:45:33.207373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all['Fare_Rate'] = pd.cut(df_all['Fare'][:891], bins=range(0, 526, 25), labels=[f'{i}-{i+24}' for i in range(0, 525, 25)])\n",
    "\n",
    "# Calculate the survival rate for each fare group\n",
    "fare_group_stats = df_all.groupby('Fare_Rate')['Survived'].agg(['mean', 'count']).reset_index()\n",
    "fare_group_stats.columns = ['Fare_Rate', 'Survival Rate', 'Count']\n",
    "\n",
    "# Print the results\n",
    "print(fare_group_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bf8e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:33.382029Z",
     "iopub.status.busy": "2023-12-29T11:45:33.381614Z",
     "iopub.status.idle": "2023-12-29T11:45:33.679733Z",
     "shell.execute_reply": "2023-12-29T11:45:33.678805Z"
    },
    "papermill": {
     "duration": 0.352625,
     "end_time": "2023-12-29T11:45:33.682144",
     "exception": false,
     "start_time": "2023-12-29T11:45:33.329519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all['FareGroup'] = pd.cut(df_all['Fare'], bins=[0, 25, 74, float('inf')],\n",
    "                             labels=['low', 'medium', 'high'])\n",
    "\n",
    "# Calculate the survival rate for each fare group\n",
    "fare_group_stats = df_all.groupby('FareGroup')['Survived'].mean().reset_index()\n",
    "\n",
    "# Print the results\n",
    "print(fare_group_stats)\n",
    "\n",
    "# Plot the survival rate for each fare group with the new labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='FareGroup', y='Survived', data=fare_group_stats, color='skyblue')\n",
    "plt.title('Survival Rate by Fare Group')\n",
    "plt.xlabel('Fare Group')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089dbf77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:33.788602Z",
     "iopub.status.busy": "2023-12-29T11:45:33.787951Z",
     "iopub.status.idle": "2023-12-29T11:45:34.098345Z",
     "shell.execute_reply": "2023-12-29T11:45:34.096891Z"
    },
    "papermill": {
     "duration": 0.366197,
     "end_time": "2023-12-29T11:45:34.101153",
     "exception": false,
     "start_time": "2023-12-29T11:45:33.734956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all['AgeGroup'] = pd.cut(df_all['Age'], bins=[0, 12, 18, 30, 50, 100], labels=['Child', 'Teenager', 'Young Adult', 'Adult', 'Senior'])\n",
    "\n",
    "# Calculate the survival rate for each age group\n",
    "age_group_stats = df_all.groupby('AgeGroup')['Survived'].mean().reset_index()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='AgeGroup', y='Survived', data=age_group_stats, palette='viridis')\n",
    "plt.title('Survival Rate by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789615cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:34.209917Z",
     "iopub.status.busy": "2023-12-29T11:45:34.209009Z",
     "iopub.status.idle": "2023-12-29T11:45:34.219477Z",
     "shell.execute_reply": "2023-12-29T11:45:34.218190Z"
    },
    "papermill": {
     "duration": 0.068087,
     "end_time": "2023-12-29T11:45:34.222186",
     "exception": false,
     "start_time": "2023-12-29T11:45:34.154099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all = pd.get_dummies(df_all, columns=['FareGroup', 'AgeGroup', 'Family_Size_Grouped'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2373f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:34.329665Z",
     "iopub.status.busy": "2023-12-29T11:45:34.329237Z",
     "iopub.status.idle": "2023-12-29T11:45:34.373479Z",
     "shell.execute_reply": "2023-12-29T11:45:34.372233Z"
    },
    "papermill": {
     "duration": 0.100701,
     "end_time": "2023-12-29T11:45:34.375925",
     "exception": false,
     "start_time": "2023-12-29T11:45:34.275224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all.head(-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50058148",
   "metadata": {
    "papermill": {
     "duration": 0.052859,
     "end_time": "2023-12-29T11:45:34.481956",
     "exception": false,
     "start_time": "2023-12-29T11:45:34.429097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Building and Tuning Machine Learning Models\n",
    "\n",
    "In this analysis, we aim to develop predictive models using four different machine learning algorithms: Decision Trees, Random Forest, XGBoost, and Support Vector Machines (SVM). Each of these models offers unique advantages and characteristics that can be leveraged to predict outcomes based on the Titanic dataset.\n",
    "\n",
    "## Decision Trees\n",
    "Decision Trees are versatile models that recursively split the dataset based on features, creating a tree-like structure to make predictions. They are interpretable and can capture complex relationships within the data.\n",
    "\n",
    "## Random Forest\n",
    "Random Forest is an ensemble method that combines multiple decision trees to improve predictive performance. By aggregating the results of individual trees, Random Forest tends to generalize well and provides robust predictions.\n",
    "\n",
    "## XGBoost\n",
    "XGBoost (Extreme Gradient Boosting) is a powerful gradient boosting algorithm known for its speed and efficiency. It sequentially builds trees, minimizing errors of the previous ones, and can handle missing data and regularization.\n",
    "\n",
    "## Support Vector Machines (SVM)\n",
    "SVM is a supervised learning algorithm that classifies data points by finding the optimal hyperplane that maximally separates different classes. It is particularly effective in high-dimensional spaces and is well-suited for binary classification tasks.\n",
    "\n",
    "In the subsequent sections, we will build and train each model, followed by hyperparameter tuning to optimize their performance on the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541018be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:34.591418Z",
     "iopub.status.busy": "2023-12-29T11:45:34.590971Z",
     "iopub.status.idle": "2023-12-29T11:45:34.617840Z",
     "shell.execute_reply": "2023-12-29T11:45:34.616666Z"
    },
    "papermill": {
     "duration": 0.084144,
     "end_time": "2023-12-29T11:45:34.620599",
     "exception": false,
     "start_time": "2023-12-29T11:45:34.536455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop columns\n",
    "columns_to_drop = ['Name', 'Age', 'Ticket', 'Fare', 'Initial', 'PassengerId', 'Fare_Rate','Family_Size']\n",
    "df_all = df_all.drop(columns_to_drop, axis=1)\n",
    "df_all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8558a32",
   "metadata": {
    "papermill": {
     "duration": 0.053355,
     "end_time": "2023-12-29T11:45:34.728060",
     "exception": false,
     "start_time": "2023-12-29T11:45:34.674705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de1b85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:34.837600Z",
     "iopub.status.busy": "2023-12-29T11:45:34.837158Z",
     "iopub.status.idle": "2023-12-29T11:45:34.847617Z",
     "shell.execute_reply": "2023-12-29T11:45:34.846545Z"
    },
    "papermill": {
     "duration": 0.067683,
     "end_time": "2023-12-29T11:45:34.850070",
     "exception": false,
     "start_time": "2023-12-29T11:45:34.782387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting df_all_binned back into training and test sets\n",
    "df_train = df_all.iloc[:891, :].reset_index(drop=True)\n",
    "df_test = df_all.iloc[891: :].reset_index(drop=True)\n",
    "\n",
    "# Display the shapes of the resulting DataFrames\n",
    "print(\"Training set shape:\", df_train.shape)\n",
    "print(\"Testing set shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656990e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:34.961625Z",
     "iopub.status.busy": "2023-12-29T11:45:34.960452Z",
     "iopub.status.idle": "2023-12-29T11:45:36.666854Z",
     "shell.execute_reply": "2023-12-29T11:45:36.665869Z"
    },
    "papermill": {
     "duration": 1.768127,
     "end_time": "2023-12-29T11:45:36.672573",
     "exception": false,
     "start_time": "2023-12-29T11:45:34.904446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(df_train.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ca651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:36.801573Z",
     "iopub.status.busy": "2023-12-29T11:45:36.800766Z",
     "iopub.status.idle": "2023-12-29T11:45:37.054714Z",
     "shell.execute_reply": "2023-12-29T11:45:37.053861Z"
    },
    "papermill": {
     "duration": 0.321623,
     "end_time": "2023-12-29T11:45:37.057090",
     "exception": false,
     "start_time": "2023-12-29T11:45:36.735467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the percentage of survived and not survived passengers\n",
    "survived_percentage = df_train['Survived'].mean() * 100\n",
    "not_survived_percentage = 100 - survived_percentage\n",
    "\n",
    "# Create a bar plot\n",
    "plt.bar(['Survived', 'Not Survived'], [survived_percentage, not_survived_percentage], color=['green', 'red'])\n",
    "plt.title('Percentage of Survived and Not Survived Passengers')\n",
    "plt.xlabel('Survival Status')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25821e0",
   "metadata": {
    "papermill": {
     "duration": 0.062829,
     "end_time": "2023-12-29T11:45:37.182408",
     "exception": false,
     "start_time": "2023-12-29T11:45:37.119579",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Class Imbalance and Its Impact on Model Performance\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Class imbalance occurs when the distribution of classes in a dataset is not uniform, meaning one class significantly outnumbers the others. In the context of binary classification, it often refers to a situation where one class is the majority (negative class), and the other is the minority (positive class). This imbalance can have a profound impact on machine learning models, leading to biased predictions and decreased performance.\n",
    "\n",
    "## Effects of Class Imbalance\n",
    "\n",
    "### 1. **Model Bias:**\n",
    "   - Imbalanced datasets can lead to biased models that favor the majority class, as the model tends to learn more from the prevalent class.\n",
    "\n",
    "### 2. **Poor Generalization:**\n",
    "   - Models trained on imbalanced data may struggle to generalize well to new, unseen data, especially for the minority class.\n",
    "\n",
    "### 3. **Misleading Evaluation Metrics:**\n",
    "   - Traditional accuracy may not be an informative metric, as a model predicting only the majority class could achieve high accuracy. Therefore, alternative metrics like precision, recall, and F1 score become crucial.\n",
    "\n",
    "### 4. **Ineffective Learning:**\n",
    "   - The minority class may not receive sufficient attention during model training, leading to poor performance in predicting instances of that class.\n",
    "\n",
    "## Approach with 4 Models\n",
    "\n",
    "In our analysis, we will explore the impact of class imbalance on four different machine learning models:\n",
    "\n",
    "1. **Decision Trees:**\n",
    "   - Decision trees are prone to favor the majority class in imbalanced datasets. We will evaluate their performance and discuss potential tuning strategies.\n",
    "\n",
    "2. **Random Forest:**\n",
    "   - Random forests, being an ensemble of decision trees, also face challenges with class imbalance. We will explore hyperparameter tuning to mitigate these issues.\n",
    "\n",
    "3. **XGBoost:**\n",
    "   - XGBoost is known for its robustness, but it's essential to assess its performance in the presence of class imbalance. We will fine-tune its parameters to achieve better results.\n",
    "\n",
    "4. **Support Vector Machines (SVM):**\n",
    "   - SVMs may be affected by imbalanced datasets, particularly if not configured correctly. We will optimize SVM hyperparameters to enhance its performance.\n",
    "\n",
    "By systematically addressing class imbalance and optimizing model parameters, we aim to improve the overall predictive capabilities of these models on imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44068bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:37.311015Z",
     "iopub.status.busy": "2023-12-29T11:45:37.310531Z",
     "iopub.status.idle": "2023-12-29T11:45:37.337884Z",
     "shell.execute_reply": "2023-12-29T11:45:37.336934Z"
    },
    "papermill": {
     "duration": 0.093876,
     "end_time": "2023-12-29T11:45:37.340525",
     "exception": false,
     "start_time": "2023-12-29T11:45:37.246649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train['Survived'] = df_train['Survived'].astype('int64')\n",
    "\n",
    "X = df_train.drop('Survived', axis=1)\n",
    "y = df_train['Survived']\n",
    "\n",
    "SEED = 0\n",
    "\n",
    "# Instantiate the oversampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Apply oversampling to the training set only\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled training data into training and testing sets with stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_resampled, y_train_resampled, test_size=0.25, random_state=42, stratify=y_train_resampled)\n",
    "\n",
    "# Display the shapes of the resulting sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a4277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:37.470141Z",
     "iopub.status.busy": "2023-12-29T11:45:37.469302Z",
     "iopub.status.idle": "2023-12-29T11:45:37.714019Z",
     "shell.execute_reply": "2023-12-29T11:45:37.712780Z"
    },
    "papermill": {
     "duration": 0.312256,
     "end_time": "2023-12-29T11:45:37.716728",
     "exception": false,
     "start_time": "2023-12-29T11:45:37.404472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check balanced dataset\n",
    "# Calculate the percentage of survived and not survived passengers\n",
    "survived_percentage = y_train_resampled.mean() * 100\n",
    "not_survived_percentage = 100 - survived_percentage\n",
    "\n",
    "# Create a bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(['Survived', 'Not Survived'], [survived_percentage, not_survived_percentage])\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Percentage of Survived and Not Survived Passengers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e33de0",
   "metadata": {
    "papermill": {
     "duration": 0.06256,
     "end_time": "2023-12-29T11:45:37.843655",
     "exception": false,
     "start_time": "2023-12-29T11:45:37.781095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Support functions to evaluate models and save score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44233b15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:37.973579Z",
     "iopub.status.busy": "2023-12-29T11:45:37.972880Z",
     "iopub.status.idle": "2023-12-29T11:45:37.988239Z",
     "shell.execute_reply": "2023-12-29T11:45:37.987168Z"
    },
    "papermill": {
     "duration": 0.0835,
     "end_time": "2023-12-29T11:45:37.990844",
     "exception": false,
     "start_time": "2023-12-29T11:45:37.907344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating a confusion matrix display function\n",
    "def display_confusion_matrix_and_metrics(y_true, y_pred):\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Set a custom color palette\n",
    "    cmap = 'summer' #sns.diverging_palette(220, 20, as_cmap=True)\n",
    "\n",
    "    # Display the confusion matrix as a heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=cmap, cbar=True, annot_kws={\"size\": 16})\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# calculate metrics for model\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    # Create a dictionary with metric names and values\n",
    "    metrics_dict = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    \n",
    "    # Display evaluation metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    return metrics_dict\n",
    "\n",
    "# Create an empty DataFrame for storing model results\n",
    "model_results = pd.DataFrame(columns=['Model', 'Accuracy', 'F1 Score', 'Precision', 'Recall'])\n",
    "\n",
    "# Define the add_results function\n",
    "def add_results(model_name, metrics_dict):\n",
    "    \"\"\"\n",
    "    Add model results to the model_results DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - model_name: Name of the model.\n",
    "    - metrics_dict: Dictionary containing model evaluation metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    global model_results  # Declare model_results as a global variable\n",
    "\n",
    "    # Create a new row with model results\n",
    "    new_row = pd.DataFrame({'Model': [model_name],\n",
    "                            'Accuracy': [metrics_dict['accuracy']],\n",
    "                            'F1 Score': [metrics_dict['f1']],\n",
    "                            'Precision': [metrics_dict['precision']],\n",
    "                            'Recall': [metrics_dict['recall']]})\n",
    "\n",
    "    # Append the new row to the model_results DataFrame\n",
    "    model_results = pd.concat([model_results, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb155b",
   "metadata": {
    "papermill": {
     "duration": 0.063087,
     "end_time": "2023-12-29T11:45:38.118754",
     "exception": false,
     "start_time": "2023-12-29T11:45:38.055667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Decision Trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f651c76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:38.253284Z",
     "iopub.status.busy": "2023-12-29T11:45:38.252869Z",
     "iopub.status.idle": "2023-12-29T11:45:38.269909Z",
     "shell.execute_reply": "2023-12-29T11:45:38.269009Z"
    },
    "papermill": {
     "duration": 0.086162,
     "end_time": "2023-12-29T11:45:38.272901",
     "exception": false,
     "start_time": "2023-12-29T11:45:38.186739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build and Train\n",
    "decision_tree = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "# Fit the model on the training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f57e20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:38.400642Z",
     "iopub.status.busy": "2023-12-29T11:45:38.399825Z",
     "iopub.status.idle": "2023-12-29T11:45:38.888665Z",
     "shell.execute_reply": "2023-12-29T11:45:38.887359Z"
    },
    "papermill": {
     "duration": 0.555224,
     "end_time": "2023-12-29T11:45:38.891200",
     "exception": false,
     "start_time": "2023-12-29T11:45:38.335976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "display_confusion_matrix_and_metrics(y_test,y_pred)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "\n",
    "add_results(\"decision_trees\", metrics)\n",
    "\n",
    "model_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace0ade",
   "metadata": {
    "papermill": {
     "duration": 0.064175,
     "end_time": "2023-12-29T11:45:39.019734",
     "exception": false,
     "start_time": "2023-12-29T11:45:38.955559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4897b7c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:39.150656Z",
     "iopub.status.busy": "2023-12-29T11:45:39.149920Z",
     "iopub.status.idle": "2023-12-29T11:45:39.427348Z",
     "shell.execute_reply": "2023-12-29T11:45:39.426187Z"
    },
    "papermill": {
     "duration": 0.345623,
     "end_time": "2023-12-29T11:45:39.430254",
     "exception": false,
     "start_time": "2023-12-29T11:45:39.084631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build and Train\n",
    "rf = RandomForestClassifier(random_state=SEED)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ed1c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:39.560327Z",
     "iopub.status.busy": "2023-12-29T11:45:39.559938Z",
     "iopub.status.idle": "2023-12-29T11:45:39.888602Z",
     "shell.execute_reply": "2023-12-29T11:45:39.887354Z"
    },
    "papermill": {
     "duration": 0.397614,
     "end_time": "2023-12-29T11:45:39.891452",
     "exception": false,
     "start_time": "2023-12-29T11:45:39.493838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "display_confusion_matrix_and_metrics(y_test,y_pred)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "\n",
    "add_results(\"random_forest\", metrics)\n",
    "\n",
    "model_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c6d4c7",
   "metadata": {
    "papermill": {
     "duration": 0.064386,
     "end_time": "2023-12-29T11:45:40.020906",
     "exception": false,
     "start_time": "2023-12-29T11:45:39.956520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ae361",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:40.152960Z",
     "iopub.status.busy": "2023-12-29T11:45:40.152259Z",
     "iopub.status.idle": "2023-12-29T11:45:40.296023Z",
     "shell.execute_reply": "2023-12-29T11:45:40.295015Z"
    },
    "papermill": {
     "duration": 0.212514,
     "end_time": "2023-12-29T11:45:40.298714",
     "exception": false,
     "start_time": "2023-12-29T11:45:40.086200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build and Train\n",
    "xgb = XGBClassifier(objective='binary:logistic', random_state=SEED)\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36524c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:40.432989Z",
     "iopub.status.busy": "2023-12-29T11:45:40.431752Z",
     "iopub.status.idle": "2023-12-29T11:45:40.752423Z",
     "shell.execute_reply": "2023-12-29T11:45:40.751127Z"
    },
    "papermill": {
     "duration": 0.389321,
     "end_time": "2023-12-29T11:45:40.754942",
     "exception": false,
     "start_time": "2023-12-29T11:45:40.365621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "display_confusion_matrix_and_metrics(y_test,y_pred)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "\n",
    "add_results(\"xgboost\", metrics)\n",
    "\n",
    "model_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b703045",
   "metadata": {
    "papermill": {
     "duration": 0.065886,
     "end_time": "2023-12-29T11:45:40.886530",
     "exception": false,
     "start_time": "2023-12-29T11:45:40.820644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45789aee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:41.025919Z",
     "iopub.status.busy": "2023-12-29T11:45:41.025427Z",
     "iopub.status.idle": "2023-12-29T11:45:41.068556Z",
     "shell.execute_reply": "2023-12-29T11:45:41.067493Z"
    },
    "papermill": {
     "duration": 0.11524,
     "end_time": "2023-12-29T11:45:41.071500",
     "exception": false,
     "start_time": "2023-12-29T11:45:40.956260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build and Train\n",
    "svm = SVC(random_state=SEED)\n",
    "\n",
    "# Fit the model on the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9dd3f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:41.207215Z",
     "iopub.status.busy": "2023-12-29T11:45:41.206819Z",
     "iopub.status.idle": "2023-12-29T11:45:41.570980Z",
     "shell.execute_reply": "2023-12-29T11:45:41.569949Z"
    },
    "papermill": {
     "duration": 0.435476,
     "end_time": "2023-12-29T11:45:41.573373",
     "exception": false,
     "start_time": "2023-12-29T11:45:41.137897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "display_confusion_matrix_and_metrics(y_test,y_pred)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "\n",
    "add_results(\"svm\", metrics)\n",
    "\n",
    "model_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f7095",
   "metadata": {
    "papermill": {
     "duration": 0.067304,
     "end_time": "2023-12-29T11:45:41.709545",
     "exception": false,
     "start_time": "2023-12-29T11:45:41.642241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431a0ff5",
   "metadata": {
    "papermill": {
     "duration": 0.068389,
     "end_time": "2023-12-29T11:45:41.845580",
     "exception": false,
     "start_time": "2023-12-29T11:45:41.777191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Scoring in Cross-Validation\n",
    "\n",
    "When performing cross-validation to tune hyperparameters, you need to choose a scoring metric to evaluate the performance of different parameter combinations. The choice of scoring metric depends on the nature of your problem:\n",
    "\n",
    "- For classification problems, common scoring metrics include:\n",
    "  - 'accuracy': Percentage of correct predictions.\n",
    "  - 'precision': Proportion of true positive predictions among all positive predictions.\n",
    "  - 'recall': Proportion of true positive predictions among all actual positive instances.\n",
    "  - 'f1': Harmonic mean of precision and recall.\n",
    "  \n",
    "**We are going to use accuracy for our models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b068d3",
   "metadata": {
    "papermill": {
     "duration": 0.066901,
     "end_time": "2023-12-29T11:45:41.979240",
     "exception": false,
     "start_time": "2023-12-29T11:45:41.912339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Decision Tree Tuning\n",
    "## Decision Tree Hyperparameters\n",
    "\n",
    "The following hyperparameters are considered for tuning the Decision Tree model:\n",
    "\n",
    "### `max_depth`\n",
    "- **Description**: Maximum depth of the tree.\n",
    "- **Impact**: Controls the depth of the tree. Deeper trees can capture more complex patterns but may lead to overfitting. `None` allows the tree to expand until all leaves are pure or contain less than `min_samples_split` samples.\n",
    "\n",
    "### `min_samples_split`\n",
    "- **Description**: Minimum number of samples required to split an internal node.\n",
    "- **Impact**: Determines how many samples are needed to make a new split. Higher values prevent creating nodes that are too specific, reducing the risk of overfitting.\n",
    "\n",
    "### `min_samples_leaf`\n",
    "- **Description**: Minimum number of samples required to be at a leaf node.\n",
    "- **Impact**: Similar to `min_samples_split`, it controls the size of the leaf. Larger leaf sizes smooth the model and can improve generalization by preventing overfitting.\n",
    "\n",
    "### `max_features`\n",
    "- **Description**: Number of features to consider when looking for the best split.\n",
    "- **Impact**: Defines how many features are considered for each split. `None` uses all features, while `'sqrt'` and `'log2'` use a subset, adding randomness and potentially improving generalization.\n",
    "\n",
    "### `criterion`\n",
    "- **Description**: The function used to measure the quality of a split.\n",
    "- **Impact**: 'gini' uses Gini impurity as the criterion, while 'entropy' uses information gain. Different criteria can lead to different performance and tree structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a2ca3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:42.118286Z",
     "iopub.status.busy": "2023-12-29T11:45:42.117869Z",
     "iopub.status.idle": "2023-12-29T11:45:53.044103Z",
     "shell.execute_reply": "2023-12-29T11:45:53.042521Z"
    },
    "papermill": {
     "duration": 11.000387,
     "end_time": "2023-12-29T11:45:53.047061",
     "exception": false,
     "start_time": "2023-12-29T11:45:42.046674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "dt = DecisionTreeClassifier(random_state = SEED)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1'}\n",
    "\n",
    "# Set up the grid search with 'accuracy' as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring=scoring,refit='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Getting the best parameters and the corresponding best accuracy\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c719c5f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:53.188925Z",
     "iopub.status.busy": "2023-12-29T11:45:53.188404Z",
     "iopub.status.idle": "2023-12-29T11:45:53.206523Z",
     "shell.execute_reply": "2023-12-29T11:45:53.205332Z"
    },
    "papermill": {
     "duration": 0.089943,
     "end_time": "2023-12-29T11:45:53.209584",
     "exception": false,
     "start_time": "2023-12-29T11:45:53.119641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimal parameters for DecisionTreeClassifier\n",
    "dt_opt = DecisionTreeClassifier(criterion='entropy', \n",
    "                                max_depth=10, \n",
    "                                max_features=None, \n",
    "                                min_samples_leaf=1, \n",
    "                                min_samples_split=15,\n",
    "                                random_state=SEED)\n",
    "\n",
    "# Fit the optimal model\n",
    "dt_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = dt_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac2834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:53.346340Z",
     "iopub.status.busy": "2023-12-29T11:45:53.345892Z",
     "iopub.status.idle": "2023-12-29T11:45:53.788003Z",
     "shell.execute_reply": "2023-12-29T11:45:53.786792Z"
    },
    "papermill": {
     "duration": 0.513866,
     "end_time": "2023-12-29T11:45:53.790788",
     "exception": false,
     "start_time": "2023-12-29T11:45:53.276922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = dt_opt.feature_importances_\n",
    "\n",
    "forest_importances = pd.Series(importances, index=X_test.columns).sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3458b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:53.930020Z",
     "iopub.status.busy": "2023-12-29T11:45:53.929562Z",
     "iopub.status.idle": "2023-12-29T11:45:54.255789Z",
     "shell.execute_reply": "2023-12-29T11:45:54.254471Z"
    },
    "papermill": {
     "duration": 0.399233,
     "end_time": "2023-12-29T11:45:54.258603",
     "exception": false,
     "start_time": "2023-12-29T11:45:53.859370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "display_confusion_matrix_and_metrics(y_test,y_pred)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "\n",
    "add_results(\"decision_trees_tuned\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1116686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:54.398489Z",
     "iopub.status.busy": "2023-12-29T11:45:54.398052Z",
     "iopub.status.idle": "2023-12-29T11:45:54.413501Z",
     "shell.execute_reply": "2023-12-29T11:45:54.412272Z"
    },
    "papermill": {
     "duration": 0.087229,
     "end_time": "2023-12-29T11:45:54.416079",
     "exception": false,
     "start_time": "2023-12-29T11:45:54.328850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d3975",
   "metadata": {
    "papermill": {
     "duration": 0.068741,
     "end_time": "2023-12-29T11:45:54.558563",
     "exception": false,
     "start_time": "2023-12-29T11:45:54.489822",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tuning Random Forest\n",
    "\n",
    "## Random Forest Hyperparameters\n",
    "\n",
    "The following hyperparameters are considered for tuning the Random Forest model:\n",
    "\n",
    "### `n_estimators`\n",
    "- **Description**: Number of trees in the forest.\n",
    "- **Impact**: More trees can lead to better performance but increase computational cost. Fewer trees are faster but may not capture all the patterns in the data.\n",
    "\n",
    "### `max_depth`\n",
    "- **Description**: Maximum depth of each tree.\n",
    "- **Impact**: Controls the depth of each tree. Deeper trees can capture more complex patterns but may lead to overfitting. `None` allows trees to grow until all leaves are pure or contain less than `min_samples_split` samples.\n",
    "\n",
    "### `min_samples_split`\n",
    "- **Description**: Minimum number of samples required to split an internal node.\n",
    "- **Impact**: Determines the minimum number of samples needed to split a node. Higher values prevent the creation of nodes that are too specific, which can reduce overfitting.\n",
    "\n",
    "### `min_samples_leaf`\n",
    "- **Description**: Minimum number of samples required to be at a leaf node.\n",
    "- **Impact**: Similar to `min_samples_split`, it controls the size of the leaf nodes. Larger values can help improve model generalization and prevent overfitting.\n",
    "\n",
    "### `max_features`\n",
    "- **Description**: Number of features to consider when looking for the best split.\n",
    "- **Impact**: Determines how many features are considered for finding the best split at each node. `None` uses all features; `'sqrt'` and `'log2'` reduce the number of features, adding randomness and potentially improving model performance.\n",
    "\n",
    "### `bootstrap`\n",
    "- **Description**: Method for sampling data points (with or without replacement).\n",
    "- **Impact**: `True` indicates bootstrapping samples (with replacement) for building trees, which is typical in Random Forest. `False` uses the whole dataset to build each tree, which can reduce randomness but increase variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fab3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:45:54.698213Z",
     "iopub.status.busy": "2023-12-29T11:45:54.697783Z",
     "iopub.status.idle": "2023-12-29T11:51:48.419349Z",
     "shell.execute_reply": "2023-12-29T11:51:48.417912Z"
    },
    "papermill": {
     "duration": 353.863726,
     "end_time": "2023-12-29T11:51:48.491463",
     "exception": false,
     "start_time": "2023-12-29T11:45:54.627737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "rf = RandomForestClassifier(random_state = SEED)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 300, 500 , 1000],\n",
    "    'max_depth': [3, 10, 20],\n",
    "    'min_samples_split': [5, 10],\n",
    "    'min_samples_leaf': [1, 5],\n",
    "    'max_features': [ None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1'}\n",
    "\n",
    "# Set up the grid search with 'accuracy' as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring=scoring , refit='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Getting the best parameters and the corresponding best accuracy\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "print(\"Best Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd15598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:51:48.632734Z",
     "iopub.status.busy": "2023-12-29T11:51:48.632268Z",
     "iopub.status.idle": "2023-12-29T11:51:49.541824Z",
     "shell.execute_reply": "2023-12-29T11:51:49.540756Z"
    },
    "papermill": {
     "duration": 0.982671,
     "end_time": "2023-12-29T11:51:49.544544",
     "exception": false,
     "start_time": "2023-12-29T11:51:48.561873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimal parameters on GridSearchCV.\n",
    "rf_opt = RandomForestClassifier(n_estimators = 300, max_depth = 20, \n",
    "                                min_samples_leaf = 1, min_samples_split = 10,\n",
    "                                max_features=None,random_state = SEED)\n",
    "\n",
    "# Fit the optimal model.\n",
    "rf_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set.\n",
    "y_pred = rf_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dd497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:51:49.684335Z",
     "iopub.status.busy": "2023-12-29T11:51:49.683907Z",
     "iopub.status.idle": "2023-12-29T11:51:50.139129Z",
     "shell.execute_reply": "2023-12-29T11:51:50.138199Z"
    },
    "papermill": {
     "duration": 0.528632,
     "end_time": "2023-12-29T11:51:50.141910",
     "exception": false,
     "start_time": "2023-12-29T11:51:49.613278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = rf_opt.feature_importances_\n",
    "\n",
    "forest_importances = pd.Series(importances, index=X_test.columns).sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6347ebea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:51:50.285542Z",
     "iopub.status.busy": "2023-12-29T11:51:50.284743Z",
     "iopub.status.idle": "2023-12-29T11:51:50.604626Z",
     "shell.execute_reply": "2023-12-29T11:51:50.603211Z"
    },
    "papermill": {
     "duration": 0.394681,
     "end_time": "2023-12-29T11:51:50.607150",
     "exception": false,
     "start_time": "2023-12-29T11:51:50.212469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "display_confusion_matrix_and_metrics(y_test, y_pred)\n",
    "# Compute metrics\n",
    "metrics = calculate_metrics(y_test, y_pred)\n",
    "# Add model results to the data frames \n",
    "add_results('random_forest_tuned', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b6cb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:51:50.753758Z",
     "iopub.status.busy": "2023-12-29T11:51:50.753266Z",
     "iopub.status.idle": "2023-12-29T11:51:50.767230Z",
     "shell.execute_reply": "2023-12-29T11:51:50.766002Z"
    },
    "papermill": {
     "duration": 0.090974,
     "end_time": "2023-12-29T11:51:50.769788",
     "exception": false,
     "start_time": "2023-12-29T11:51:50.678814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a05594",
   "metadata": {
    "papermill": {
     "duration": 0.072722,
     "end_time": "2023-12-29T11:51:50.915185",
     "exception": false,
     "start_time": "2023-12-29T11:51:50.842463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tuning XGBoost\n",
    "## XGBoost Hyperparameters\n",
    "\n",
    "XGBoost is a powerful machine learning algorithm especially for structured data. Below are key hyperparameters that are commonly tuned:\n",
    "\n",
    "### `n_estimators`\n",
    "- **Description**: Number of gradient boosted trees.\n",
    "- **Impact**: More trees can improve performance but may lead to overfitting. It's essential to balance this with the learning rate.\n",
    "\n",
    "### `learning_rate`\n",
    "- **Description**: Step size shrinkage used to prevent overfitting.\n",
    "- **Impact**: Controls the rate of learning. Smaller values make the process more conservative, requiring more trees but can lead to better final models.\n",
    "\n",
    "### `max_depth`\n",
    "- **Description**: Maximum depth of a tree.\n",
    "- **Impact**: Controls the depth of each tree. Deeper trees can model more complex patterns but can also lead to overfitting.\n",
    "\n",
    "### `subsample`\n",
    "- **Description**: Subsample ratio of the training instances.\n",
    "- **Impact**: Fraction of the training data to be used for training each tree. Lower values can help prevent overfitting.\n",
    "\n",
    "### `colsample_bytree`\n",
    "- **Description**: Subsample ratio of columns when constructing each tree.\n",
    "- **Impact**: Fraction of features to be used for each tree. Similar to `max_features` in Random Forests, it adds randomness to the model.\n",
    "\n",
    "### `gamma`\n",
    "- **Description**: Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "- **Impact**: A higher value leads to more conservative models, acting as a regularization parameter.\n",
    "\n",
    "### `reg_alpha` (L1 regularization term)\n",
    "- **Description**: L1 regularization term on weights.\n",
    "- **Impact**: Can be used for feature selection, leading to sparser trees.\n",
    "\n",
    "### `reg_lambda` (L2 regularization term)\n",
    "- **Description**: L2 regularization term on weights.\n",
    "- **Impact**: Adds regularization to the model. Helps in preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc99119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:51:51.061300Z",
     "iopub.status.busy": "2023-12-29T11:51:51.060833Z",
     "iopub.status.idle": "2023-12-29T11:52:37.839148Z",
     "shell.execute_reply": "2023-12-29T11:52:37.837917Z"
    },
    "papermill": {
     "duration": 46.920544,
     "end_time": "2023-12-29T11:52:37.908035",
     "exception": false,
     "start_time": "2023-12-29T11:51:50.987491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize XGBoost classifier\n",
    "xgb = XGBClassifier(objective='binary:logistic', random_state=SEED, use_label_encoder=False)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'max_depth': [3, 5],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1],\n",
    "    'gamma': [0, 0.1],\n",
    "    'reg_alpha': [0, 0.1],\n",
    "    'reg_lambda': [1, 2]\n",
    "}\n",
    "\n",
    "\n",
    "# Define multiple scoring metrics\n",
    "scoring = {'accuracy', 'precision', 'recall', 'f1'}\n",
    "\n",
    "# Set up GridSearchCV with multiple scoring and refit for accuracy\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring=scoring, refit='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Getting the best parameters and corresponding best accuracy\n",
    "best_parameters = grid_search.best_params_\n",
    "best_scores = grid_search.cv_results_\n",
    "\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "print(\"Best Accuracy:\", best_scores['mean_test_accuracy'][grid_search.best_index_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06988b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:52:38.053827Z",
     "iopub.status.busy": "2023-12-29T11:52:38.053340Z",
     "iopub.status.idle": "2023-12-29T11:52:38.136565Z",
     "shell.execute_reply": "2023-12-29T11:52:38.135448Z"
    },
    "papermill": {
     "duration": 0.159656,
     "end_time": "2023-12-29T11:52:38.139307",
     "exception": false,
     "start_time": "2023-12-29T11:52:37.979651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimal Hyperparameters for XGBoost\n",
    "best_params = {'colsample_bytree': 0.8, 'gamma': 0.1,\n",
    "               'learning_rate': 0.1,\n",
    "               'max_depth': 5, 'n_estimators': 100,\n",
    "               'reg_alpha': 0.1,\n",
    "               'reg_lambda': 1, 'subsample': 1}\n",
    "\n",
    "# Construct the XGBoost model with the Optimal hyperparameters\n",
    "xgb_opt = XGBClassifier(**best_params, random_state=SEED)\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033dee6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:52:38.286276Z",
     "iopub.status.busy": "2023-12-29T11:52:38.285842Z",
     "iopub.status.idle": "2023-12-29T11:52:38.744035Z",
     "shell.execute_reply": "2023-12-29T11:52:38.742707Z"
    },
    "papermill": {
     "duration": 0.534099,
     "end_time": "2023-12-29T11:52:38.746838",
     "exception": false,
     "start_time": "2023-12-29T11:52:38.212739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importances = xgb_opt.feature_importances_\n",
    "\n",
    "forest_importances = pd.Series(importances, index=X_test.columns).sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0528cc7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:52:38.897465Z",
     "iopub.status.busy": "2023-12-29T11:52:38.896996Z",
     "iopub.status.idle": "2023-12-29T11:52:39.236577Z",
     "shell.execute_reply": "2023-12-29T11:52:39.235304Z"
    },
    "papermill": {
     "duration": 0.419336,
     "end_time": "2023-12-29T11:52:39.239353",
     "exception": false,
     "start_time": "2023-12-29T11:52:38.820017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "display_confusion_matrix_and_metrics(y_test, y_pred)\n",
    "# Compute metrics\n",
    "metrics = calculate_metrics(y_test, y_pred)\n",
    "# Add model results to the data frames \n",
    "add_results('XGBoost_tuned', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ed07e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:52:39.390368Z",
     "iopub.status.busy": "2023-12-29T11:52:39.389937Z",
     "iopub.status.idle": "2023-12-29T11:52:39.406045Z",
     "shell.execute_reply": "2023-12-29T11:52:39.404664Z"
    },
    "papermill": {
     "duration": 0.094722,
     "end_time": "2023-12-29T11:52:39.408821",
     "exception": false,
     "start_time": "2023-12-29T11:52:39.314099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f314ba8",
   "metadata": {
    "papermill": {
     "duration": 0.073141,
     "end_time": "2023-12-29T11:52:39.557237",
     "exception": false,
     "start_time": "2023-12-29T11:52:39.484096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SVM TUNING\n",
    "## SVM Hyperparameters\n",
    "\n",
    "When tuning a Support Vector Machine (SVM), several key hyperparameters significantly influence the model's performance:\n",
    "\n",
    "### `C` (Regularization parameter)\n",
    "- **Description**: Controls the trade-off between creating a smooth decision boundary and classifying training points correctly. A smaller value of `C` creates a smoother decision boundary at the cost of training accuracy, whereas a larger `C` aims to classify all training examples correctly by giving the model freedom to select more samples as support vectors.\n",
    "- **Suggested Values**: `[0.01, 0.1, 1, 10, 100]`\n",
    "\n",
    "### `kernel`\n",
    "- **Description**: The type of kernel used in SVM. It defines the decision boundary between the classes. Different kernels are suitable for different types of data.\n",
    "- **Suggested Values**: `['linear', 'rbf', 'poly']`\n",
    "  - `'linear'`: Used for linearly separable data.\n",
    "  - `'rbf'` (Radial Basis Function): Useful for non-linear hyperplane.\n",
    "  - `'poly'` (Polynomial): Good for data where the relationship between features is not linear.\n",
    "\n",
    "### `gamma` (Kernel coefficient)\n",
    "- **Description**: For non-linear kernels, it defines how far the influence of a single training example reaches. High values lead to more complex models.\n",
    "- **Suggested Values**: `['scale', 'auto', 0.01, 0.1, 1]`\n",
    "  - `'scale'`: Automatically adjusts gamma based on the number of features.\n",
    "  - `'auto'`: Uses `1/n_features`.\n",
    "\n",
    "### `degree`\n",
    "- **Description**: Degree of the polynomial kernel function (`'poly'`). Ignored by all other kernels.\n",
    "- **Suggested Values**: `[2, 3, 4]`\n",
    "- **Impact**: Higher degrees mean considering more complex models (higher-order polynomials), which can lead to overfitting for some datasets.\n",
    "\n",
    "### `shrinking`\n",
    "- **Description**: A heuristic approach to simplify the calculations. True by default. When set to False, it forces the model to use the full optimization problem.\n",
    "- **Suggested Values**: `[True, False]`\n",
    "\n",
    "### `class_weight`\n",
    "- **Description**: Adjusts weights inversely proportional to class frequencies in the input data. Useful for unbalanced classes.\n",
    "- **Suggested Values**: `[None, 'balanced']`\n",
    "  - `None`: No weights are applied.\n",
    "  - `'balanced'`: Automatically adjust weights inversely proportional to class frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e9d39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:52:39.714267Z",
     "iopub.status.busy": "2023-12-29T11:52:39.713408Z",
     "iopub.status.idle": "2023-12-29T11:53:06.581175Z",
     "shell.execute_reply": "2023-12-29T11:53:06.579972Z"
    },
    "papermill": {
     "duration": 26.952221,
     "end_time": "2023-12-29T11:53:06.584147",
     "exception": false,
     "start_time": "2023-12-29T11:52:39.631926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Declare the SVM model\n",
    "svm_model = SVC(random_state=SEED)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "cv_params = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'degree': [2, 4],  # Only relevant for 'poly' kernel\n",
    "    'shrinking': [True, False],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "# Define custom scorers with zero_division parameter set to 0\n",
    "scoring_metrics = {\n",
    "    'accuracy': make_scorer(accuracy_score),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'recall': make_scorer(recall_score, zero_division=0),\n",
    "    'f1': make_scorer(f1_score, zero_division=0)\n",
    "}\n",
    "\n",
    "# Construct the GridSearch with multiple scoring metrics\n",
    "svm_grid_search = GridSearchCV(svm_model,\n",
    "                               cv_params,\n",
    "                               scoring=scoring_metrics,\n",
    "                               cv=5,\n",
    "                               refit='accuracy',\n",
    "                               n_jobs=-1  # Use parallel processing\n",
    "                              )\n",
    "\n",
    "# Fit the grid search to your data\n",
    "svm_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Getting the best parameters and corresponding best scores\n",
    "best_parameters = svm_grid_search.best_params_\n",
    "best_index = svm_grid_search.best_index_\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", best_parameters)\n",
    "print(\"Best Accuracy:\", svm_grid_search.cv_results_['mean_test_accuracy'][best_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d29eeba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:53:06.734928Z",
     "iopub.status.busy": "2023-12-29T11:53:06.733966Z",
     "iopub.status.idle": "2023-12-29T11:53:06.775795Z",
     "shell.execute_reply": "2023-12-29T11:53:06.774461Z"
    },
    "papermill": {
     "duration": 0.120393,
     "end_time": "2023-12-29T11:53:06.778745",
     "exception": false,
     "start_time": "2023-12-29T11:53:06.658352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optimal Hyperparameters for SVM\n",
    "best_params = {'C': 1, 'class_weight': None,\n",
    "               'degree': 4,\n",
    "               'gamma': 'scale',\n",
    "               'kernel': 'poly',\n",
    "               'shrinking': True}\n",
    "\n",
    "# Construct the model with the Optimal hyperparameters\n",
    "svm_opt = SVC(**best_params, random_state=SEED)\n",
    "\n",
    "# Fit the model on the training data\n",
    "svm_opt.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svm_opt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b582b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:53:06.928628Z",
     "iopub.status.busy": "2023-12-29T11:53:06.928166Z",
     "iopub.status.idle": "2023-12-29T11:53:11.667353Z",
     "shell.execute_reply": "2023-12-29T11:53:11.666190Z"
    },
    "papermill": {
     "duration": 4.817848,
     "end_time": "2023-12-29T11:53:11.670398",
     "exception": false,
     "start_time": "2023-12-29T11:53:06.852550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Feature importance using permutation importance\n",
    "importance = permutation_importance(svm_opt, X_test, y_test, n_repeats=30, random_state=SEED)\n",
    "\n",
    "# Create a DataFrame to store feature names and their importance scores\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importance.importances_mean})\n",
    "\n",
    "# Sort the DataFrame by importance values in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')\n",
    "plt.title('SVM - Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d034767",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:53:11.825769Z",
     "iopub.status.busy": "2023-12-29T11:53:11.825336Z",
     "iopub.status.idle": "2023-12-29T11:53:12.154159Z",
     "shell.execute_reply": "2023-12-29T11:53:12.152783Z"
    },
    "papermill": {
     "duration": 0.41034,
     "end_time": "2023-12-29T11:53:12.156938",
     "exception": false,
     "start_time": "2023-12-29T11:53:11.746598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "display_confusion_matrix_and_metrics(y_test, y_pred)\n",
    "# Compute metrics\n",
    "metrics = calculate_metrics(y_test, y_pred)\n",
    "# Add model results to the data frames \n",
    "add_results('svm_tuned', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03341bbd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:53:12.314292Z",
     "iopub.status.busy": "2023-12-29T11:53:12.313893Z",
     "iopub.status.idle": "2023-12-29T11:53:12.330880Z",
     "shell.execute_reply": "2023-12-29T11:53:12.329288Z"
    },
    "papermill": {
     "duration": 0.099562,
     "end_time": "2023-12-29T11:53:12.333544",
     "exception": false,
     "start_time": "2023-12-29T11:53:12.233982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_results.sort_values(by='Accuracy', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec56952",
   "metadata": {
    "papermill": {
     "duration": 0.076374,
     "end_time": "2023-12-29T11:53:12.486741",
     "exception": false,
     "start_time": "2023-12-29T11:53:12.410367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Performance Analysis\n",
    "\n",
    "The performance of various machine learning models has been evaluated based on four key metrics: Accuracy, F1 Score, Precision, and Recall. Here's a summary of their performances:\n",
    "\n",
    "| Model               | Accuracy | F1 Score | Precision | Recall  |\n",
    "|---------------------|----------|----------|-----------|---------|\n",
    "| Decision Trees      | 0.8145   | 0.8159   | 0.8071    | 0.8248  |\n",
    "| XGBoost             | 0.8145   | 0.8172   | 0.8028    | 0.8321  |\n",
    "| Random Forest (Tuned)| 0.8109   | 0.8207   | 0.7778    | 0.8686  |\n",
    "| Decision Trees (Tuned)| 0.8036   | 0.8112   | 0.7785    | 0.8467  |\n",
    "| XGBoost (Tuned)     | 0.8036   | 0.8085   | 0.7862    | 0.8321  |\n",
    "| Random Forest       | 0.8000   | 0.8097   | 0.7697    | 0.8540  |\n",
    "| SVM (Tuned)         | 0.7891   | 0.8041   | 0.7484    | 0.8686  |\n",
    "| SVM                 | 0.7782   | 0.7663   | 0.8065    | 0.7299  |\n",
    "\n",
    "### Observations and Conclusions:\n",
    "\n",
    "1. **Top Performers**: Decision Trees and XGBoost (untuned versions) share the highest accuracy and F1 scores, suggesting robust performance across both precision and recall.\n",
    "\n",
    "2. **Effect of Tuning**: Tuning the Random Forest model slightly improves its recall, making it the best model for minimizing false negatives. However, tuning Decision Trees and XGBoost results in a slight decrease in performance, indicating that the default parameters were already quite effective for this dataset.\n",
    "\n",
    "3. **Precision vs. Recall**: There is an evident trade-off between precision and recall among the models. SVM (Tuned) and Random Forest (Tuned) show higher recall but at the cost of lower precision, which might be preferable in scenarios where missing a positive instance (false negative) is more critical.\n",
    "\n",
    "4. **SVM Performance**: SVM models, both tuned and untuned, lag behind tree-based models in terms of overall accuracy and F1 score. However, the tuned SVM shows a significant improvement in recall, making it a potential choice for applications where recall is more important.\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "- For applications requiring a balance between precision and recall, **Decision Trees** and **XGBoost** are recommended.\n",
    "- In cases where high recall is more critical, consider using **Random Forest (Tuned)** or **SVM (Tuned)**.\n",
    "- Further model-specific tuning and feature engineering might yield improvements, especially for the models that didn't perform as well in their untuned state.\n",
    "\n",
    "### Practical Considerations\n",
    "\n",
    "- **Model Complexity and Training Time**: While not directly measured here, these factors are crucial in a real-world setting. Decision Trees are typically faster and simpler compared to models like XGBoost.\n",
    "\n",
    "- **Application Scenarios**: For instance, in a spam detection system, precision might be more critical to minimize legitimate emails being classified as spam. In contrast, in medical diagnosis, a high recall is usually more important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74093b1a",
   "metadata": {
    "papermill": {
     "duration": 0.07654,
     "end_time": "2023-12-29T11:53:12.640296",
     "exception": false,
     "start_time": "2023-12-29T11:53:12.563756",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Decision Tree vs. XGBoost: Pros, Cons, and Recommendation\n",
    "\n",
    "### Decision Tree\n",
    "**Pros:**\n",
    "- **Simplicity and Speed**: Decision Trees are relatively simple to understand and quick to train.\n",
    "- **Interpretability**: They offer high interpretability as the decision process can be easily visualized.\n",
    "- **Less Prone to Overfitting**: If not very deep, they are less likely to overfit compared to more complex models.\n",
    "\n",
    "**Cons:**\n",
    "- **Handling Complex Patterns**: May not capture complex patterns as effectively as ensemble methods like XGBoost.\n",
    "- **Variance**: A small change in the data can lead to a significantly different tree.\n",
    "- **Performance Ceiling**: Often have a lower performance ceiling in terms of accuracy, especially on complex datasets.\n",
    "\n",
    "### XGBoost\n",
    "**Pros:**\n",
    "- **Handling Complexity**: Excellent at handling a variety of data types, relationships, and distributions.\n",
    "- **Higher Performance**: Generally delivers higher accuracy, especially on larger and more complex datasets.\n",
    "- **Feature Importance**: Provides insights into the significance of different features for predictions.\n",
    "\n",
    "**Cons:**\n",
    "- **Interpretability**: More complex and less interpretable compared to a single Decision Tree.\n",
    "- **Training Time**: Requires more computational resources and time to train.\n",
    "- **Risk of Overfitting**: If not tuned properly, can overfit the training data.\n",
    "\n",
    "#### Considerations for Final Decision:\n",
    "- **Dataset Complexity and Size**: Opt for XGBoost for complex, large datasets; consider Decision Trees for simpler, smaller datasets.\n",
    "- **Interpretability Needs**: If you need to easily explain the model's decisions, Decision Trees are preferable.\n",
    "- **Computational Resources and Training Time**: If limited, a Decision Tree might be more practical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb56001",
   "metadata": {
    "papermill": {
     "duration": 0.084047,
     "end_time": "2023-12-29T11:53:12.802010",
     "exception": false,
     "start_time": "2023-12-29T11:53:12.717963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion and Decision\n",
    "\n",
    "After evaluating the available options, we have decided to move forward with **XGBoost** for our analysis. Despite our dataset being relatively small, XGBoost's superior capability in managing categorical variables and unraveling complex relationships between diverse features makes it a more suitable choice over Decision Trees. We anticipate that this approach will yield more accurate and insightful predictions, essential for the objectives of our project.\n",
    "\n",
    "We are therefore proceeding with the implementation of the XGBoost model in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d3cd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:53:12.959014Z",
     "iopub.status.busy": "2023-12-29T11:53:12.958531Z",
     "iopub.status.idle": "2023-12-29T11:53:13.063754Z",
     "shell.execute_reply": "2023-12-29T11:53:13.062534Z"
    },
    "papermill": {
     "duration": 0.187063,
     "end_time": "2023-12-29T11:53:13.067199",
     "exception": false,
     "start_time": "2023-12-29T11:53:12.880136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build and Train\n",
    "xgb = XGBClassifier(objective='binary:logistic', random_state=SEED, use_label_encoder=False)\n",
    "\n",
    "# Fit the model on the training data\n",
    "xgb.fit(X, y)\n",
    "\n",
    "\n",
    "df_test = df_test.drop('Survived', axis=1)\n",
    "# Make predictions on the Test data\n",
    "y_pred = xgb.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b98174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-29T11:53:13.223847Z",
     "iopub.status.busy": "2023-12-29T11:53:13.223325Z",
     "iopub.status.idle": "2023-12-29T11:53:13.243288Z",
     "shell.execute_reply": "2023-12-29T11:53:13.241996Z"
    },
    "papermill": {
     "duration": 0.100655,
     "end_time": "2023-12-29T11:53:13.246168",
     "exception": false,
     "start_time": "2023-12-29T11:53:13.145513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "# Submit the results\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\":test[\"PassengerId\"],\n",
    "        \"Survived\": y_pred})\n",
    "\n",
    "submission['Survived'] = submission['Survived'].astype('Int64')\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccd0cd8",
   "metadata": {
    "papermill": {
     "duration": 0.075742,
     "end_time": "2023-12-29T11:53:13.400916",
     "exception": false,
     "start_time": "2023-12-29T11:53:13.325174",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Acknowledgments\n",
    "\n",
    "I would like to express my gratitude to the following notebooks, which were instrumental in guiding and enhancing my analysis:\n",
    "\n",
    "1. [Titanic EDA: A comprehensive exploration of the dataset](https://www.kaggle.com/code/computervisi/titanic-eda#Sinking) by MLCV\n",
    "   - This notebook provided valuable insights into exploratory data analysis (EDA) for the Titanic dataset. It greatly influenced the way I approached feature analysis and visualization.\n",
    "\n",
    "2. [Titanic Model with 90% Accuracy](https://www.kaggle.com/code/vinothan/titanic-model-with-90-accuracy/notebook#Random-Forest-Classifier) by VK_DS\n",
    "   - This notebook presented an in-depth exploration of various machine learning models on the Titanic dataset, with a specific focus on the Random Forest Classifier. It was particularly helpful in understanding model selection and hyperparameter tuning.\n",
    "\n",
    "I appreciate the authors for their contributions to the Kaggle community, as their work significantly contributed to the success of this project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6b888",
   "metadata": {
    "papermill": {
     "duration": 0.076905,
     "end_time": "2023-12-29T11:53:13.555044",
     "exception": false,
     "start_time": "2023-12-29T11:53:13.478139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Seeking Feedback\n",
    "\n",
    "🙏 **Feedback Requested!** 🙏\n",
    "\n",
    "I welcome and appreciate feedback from the Kaggle community. If you have any suggestions, improvements, or insights regarding my analysis, please feel free to share them in the comments section.\n",
    "\n",
    "- Is there anything I might have missed in my analysis?\n",
    "- Do you have ideas for additional features or techniques that could enhance the model?\n",
    "- Any constructive criticism or tips for improvement are highly valued.\n",
    "\n",
    "Your input is crucial in the collaborative spirit of learning and growing together. Let's make this analysis better with your valuable comments! Thank you for your time and insights. 🚀\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 478.381508,
   "end_time": "2023-12-29T11:53:16.257681",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-29T11:45:17.876173",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
